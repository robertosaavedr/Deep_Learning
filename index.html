
<!doctype html>
<html lang="en">

	<head>
		<style>
			#circle {
				width: 50px;
				height: 50px;
				-webkit-border-radius: 25px;
				-moz-border-radius: 25px;
				background: #d900ff;
				margin: 10px;
			}
			p.ex1 {
  margin: 35px;
}
			#left{border: 1px;}

		</style>
		<meta charset="utf-8">

		<title>Deep Learning</title>

		<meta name="description" content="A framework for easily creating beautiful presentations using HTML">
		<meta name="author" content="Roberto Saavedra, Ducassin, Rayo">

		<meta name="apple-mobile-web-app-capable" content="yes">
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

		<meta name="viewport" content="width=device-width, initial-scale=1.0">

		<link rel="stylesheet" href="css/reset.css">
		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/black.css" id="theme">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/monokai.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>

		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">
				<section data-background-video="imagenes/sky.mp4" data-background-video-loop="loop"></section>
				<section data-background-video="imagenes/sky.mp4" data-background-video-loop="loop">
					<h1>Deep Learning</h1>
					<h3>Con Keras y TensorFlow</h3>
					<p>
						<small>Creado por Roberto Saavedra, Alejandro Rayo y Sergio Rodriguez</small>
					</p>
				</section >
                <section data-background="https://media3.giphy.com/media/EBysPyjz3BHVu/giphy.gif?cid=ecf05e47d4606f58882ed4867140e9f37daa6639bb99db11&rid=giphy.gif">
                <!--<h1>CONTENIDOS</h1>
                <h4>IA, Machine Learning y Deep Learning</h4>
                <h4>Motivación e Introducción a las redes neuronales</h4>
                <h4>Hands-On Deep Learning</h4>-->
                <p style='font-family:georgia;font-size:46px;font-style:italic;' class="fragment">IA, MACHINE LEARNING Y DEEP LEARNING</p>
                <p style='font-family:georgia;font-size:46px;font-style:italic;' class="fragment">REDES NEURONALES</p>
                <p style='font-family:georgia;font-size:46px;font-style:italic;' class="fragment">HANDS-ON DEEP LEARNING</p>


                </section>
				<section data-background="https://media3.giphy.com/media/EBysPyjz3BHVu/giphy.gif?cid=ecf05e47d4606f58882ed4867140e9f37daa6639bb99db11&rid=giphy.gif">
				</section>
				<section>
					<section>
						<h3>¿DÓNDE ENCONTRAR UN COMPORTAMIENTO INTELIGENTE?</h3>
					</section>

					<section data-background-video="imagenes\BRAIN.mp4" data-background-color="#000000" data-background-video-loop="loop">
				    </section>
				</section>
				<section data-background-color="#001A2C">
						<IMG SRC="https://miro.medium.com/max/2000/1*bhFifratH9DjKqMBTeQG5A.gif" style="background:none; border:none; box-shadow:none;">



				</section>


									</section>
				<section>
				<section >

					<IMG SRC='https://www.gstatic.com/devrel-devsite/prod/v2210deb8920cd4a55bd580441aa58e7853afc04b39a9d9ac4198e1cd7fbe04ef/tensorflow/images/lockup.svg' style="background:none; border:none; box-shadow:none;">
					<IMG SRC = 'https://s3.amazonaws.com/keras.io/img/keras-logo-2018-large-1200.png' style="background:none; border:none; box-shadow:none;">
				</section>
					<section>
					<pre class="python"><code data-trim data-line-numbers="1|3|1-3">
from tensorflow import keras

(imagenes, etiquetas), (_, _) = keras.datasets.mnist.load_data()


					</code></pre>
						<IMG SRC='imagenes\cero.png' style="background:none; border:none; box-shadow:none;" height='450' width="450">
					</section>
                    <section data-background-image='https://miro.medium.com/max/2482/0*xqJA1mCMLc7b64H1.png'>
					</section>
					<section data-background-image="imagenes/uno.svg" data-background-position="-195px">

					</section>
					<section data-background-image="imagenes/dos.svg" data-background-position="-225px">

					</section>
					<section data-background-image="imagenes/tres.svg" data-background-position="-225px">

					</section>
					<section data-background-image="imagenes/cuatro.svg" data-background-position="-280px">

					</section>
                    <section data-background-image="imagenes/ar.svg" data-background-position="-400px">
					<div style="position: absolute; zoom: 0.7; width: 60%; right: 0;">
						<pre class="python"><p class="fragment"><code data-trim data-line-numbers="1|2|3|4|1-5">
red_neuronal = keras.models.Sequential([
    keras.layers.Flatten(input_shape=[28, 28]),
    keras.layers.Dense(100, activation="sigmoid"),
    keras.layers.Dense(10, activation="softmax")
])


					</code></p></pre>
</div>
                    </section>
					<section>

					<pre class="python"><p class="fragment"><code data-trim data-line-numbers="1|2|3|1-3|5|6|7|5-7|1-7">
red_neuronal.compile(loss='sparse_categorical_crossentropy',
              optimizer=keras.optimizers.SGD(lr=0.05),
              metrics=['accuracy'])

early_stopping = keras.callbacks.EarlyStopping()
red_neuronal.fit(imagenes_entrenamiento, etiquetas_entrenamiento,
epochs=10, validation_split=0.1, callbacks=[early_stopping])
					</code></p>
						<p class='fragment'>Train on 54000 samples, validate on 6000 samples
Epoch 1/10
54000/54000 [==============================] - 4s 72us/sample
loss: 0.9310 - accuracy: 0.7128 - val_loss: 0.6660 - val_accuracy:
0.7867
Epoch 2/10
54000/54000 [==============================] - 3s 62us/sample
loss: 0.7030 - accuracy: 0.7799 - val_loss: 0.6760 - val_accuracy:
0.7887						</p>
					</pre>

</section>

					<section>
						<pre class="python" ><p class="fragment"><code class="stretch" data-trim data-line-numbers="1-11|13-15|17-20">
red_neuronal_2 = keras.models.Sequential([
    keras.layers.Flatten(input_shape=[28, 28]),
    keras.layers.BatchNormalization(),
    keras.layers.Dense(200, activation="selu",
	kernel_initializer="lecun_normal"),
    keras.layers.BatchNormalization(),
    keras.layers.Dense(100, activation="selu",
	kernel_initializer="lecun_normal"),
    keras.layers.BatchNormalization(),
    keras.layers.Dense(10, activation="softmax")
])

red_neuronal_2.compile(loss='sparse_categorical_crossentropy',
              optimizer=keras.optimizers.SGD(lr=0.05),
              metrics=['accuracy'])

red_neuronal_2.fit(imagenes_entrenamiento,
                   etiquetas_entrenamiento,epochs=10,
                   validation_split=0.1,
				   callbacks=[early_stopping])</code></p>
					</pre>
					</section>
					</section>
<section>
				<section>
<h3>REDES NEURONALES CONVOLUCIONALES</h3>
				</section>
								<section>
								<img src="imagenes/rome.jpg" style="background:none; border:none; box-shadow:none;">
								</section>
	<section data-background-color="white">
		<img src="imagenes/pez.png" style="background:none; border:none; box-shadow:none;">
	</section>
	<section data-background-color="white">
			    <img src="imagenes/capas.png" style="background:none; border:none; box-shadow:none;">

	</section>
	<section data-background-color="white">
		<img src="imagenes/filter1.png" style="background:none; border:none; box-shadow:none;height:75%; width:75%" >

	</section>
	<section data-background-color="white">
		<img src="imagenes/filter2.png" style="background:none; border:none; box-shadow:none; height:75%; width:75%" >
		<img src="imagenes/filter3.png" style="background:none; border:none; box-shadow:none; height:75%; width:75%">
	</section>
	<section data-background-color="white">
		 <img src="imagenes/pooling.png" style="background:none; border:none; box-shadow:none;">
	</section>
	<section data-background-color="white">
		 <img src="imagenes/arqui.png" style="background:none; border:none; box-shadow:none;">
	</section>

</section>

				<section>
				<section>
					<h3>MODELOS PRE-ENTRENADOS</h3>
				</section>

				<section data-background-color="black">
					<h3>RESNET-50</h3>
					<h3>+</h3>
					<IMG SRC="imagenes/inet.jpeg" style="background:none; border:none; box-shadow:none;">

				</section>
					<section>
						<IMG SRC="imagenes/castillo.jpg" style="background:none; border:none; box-shadow:none; height:40%; width:40%">
						<IMG SRC="imagenes/perro.jpg" style="background:none; border:none; box-shadow:none; height:40%; width:40%">

					</section>
					<section>
						<div style="zoom: 0.40;">
						<pre class="python" ><code class="stretch" data-trim data-line-numbers="1-3|6-8|10-11|13|15-16|1-16">
from urllib.request import urlopen, Request
import matplotlib.pyplot as plt
import tensorflow as tf


headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.3'}
imagen_perro = plt.imread(urlopen(Request('https://cdn.pixabay.com/photo/2015/11/17/13/13/dogue-de-bordeaux-1047521_1280.jpg', headers=headers)), format='jpg')
castillo = plt.imread(urlopen(Request('https://www.audioguiaroma.com/imagenes/castillo-san-angelo.jpg', headers=headers)), format='jpg')

imagen_perro_crop = tf.image.resize_with_pad(imagen_perro, 224,224, antialias=True)
castillo_crop = tf.image.resize_with_pad(castillo, 224, 224,antialias=True)

imagenes = keras.applications.resnet50.preprocess_input(np.array([imagen_perro_crop, castillo_crop]))

neural_network_on_steroids = keras.applications.resnet50.ResNet50(weights="imagenet")
pred = neural_network_on_steroids.predict(imagenes)
						</code>
					</pre>
						</div>
						<p class="fragment"><table style="zoom:70%" class="fragment">
						<thead>
							<tr>

								<th>Predicciones para perro</th>
								<th>Probabilidad</th>
								<th>Predicciones para castillo</th>
								<th>Probabilidad</th>

							</tr>
						</thead>
						<tbody>
							<tr>
								<td>vizsla </td>
								<td>58.95%</td>
								<td>palace</td>
								<td>45.57%</td>
							</tr>
							<tr>
								<td>labrador_retriever</td>
								<td>29.05%</td>
								<td>dome</td>
								<td>23.81%</td>

							</tr>
							<tr>
								<td>bull_mastif</td>
								<td>1.68%</td>
								<td>castle</td>
								<td>12.66%</td>

							</tr>

						</tbody>
					</table></p>
					</section>
</section>


				<section>
					<section>
						<a href="https://www.youtube.com/playlist?list=PLd7R6J6iS6r4sITNFQ3ZMvj7BzWqTXfIe" target="_blank"><p class="fragment">3Blue1Brown: Deep Learning</p></a>
						<a href="https://www.youtube.com/playlist?list=PL-Ogd76BhmcDxef4liOGXGXLL-4h65bs4" target="_blank"><p class="fragment">Dot CSV: Aprendiendo Inteligencia Artificial</p></a>
						<a href="https://www.coursera.org/learn/machine-learning?skipBrowseRedirect=true" target="_blank"><p class="fragment">Standford Machine Learning taught by Andrew NG </p></a>
						<a href="https://books.google.es/books?id=HHetDwAAQBAJ&pg=PA480&lpg=PA480&dq=resize+images+tensorflow&source=bl&ots=0Kvm0rnlRr&sig=ACfU3U0Bp63g72bGIIbKQG8iZkJ3QxFOyA&hl=es&sa=X&ved=2ahUKEwjF65v-95XpAhWNAWMBHTujDW44ChDoATAHegQIChAB#v=twopage&q&f=false" target="_blank"> <p class="fragment">Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow </p>
</a>
						<a href="http://introtodeeplearning.com/" target="_blank"><p class="fragment">MIT Introduction to Deep Learning</p>
 </a>




						</section>
					<section data-background-color="#100e0f">
						<a href="https://github.com/robertosaavedr/deep_learning" target="_blank"><img src="imagenes/github.png" style="background:none; border:none; box-shadow:none; height:20%; width:20%"></a>
						<a href="" target="_blank"><img src="imagenes/kaggle.png" style="background:none; border:none; box-shadow:none;"></a>

					</section>

				<section>
					😘
				</section>

</section>









			</div>

		</div>

		<script src="js/reveal.js"></script>

		<script>

			// More info https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				multiplex: {
		        url: 'https://reveal-js-multiplex-ccjbegmaii.now.sh/token',
		        id: '947881096f937525',
		        secret: Reveal.getQueryHash().s || null
				},
				controls: true,
				progress: true,
				center: true,
				hash: true,

				transition: 'slide', // none/fade/slide/convex/concave/zoom

				// More info https://github.com/hakimel/reveal.js#dependencies
				dependencies: [
					{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js' },
					{ src: 'plugin/search/search.js', async: true },
					{ src: 'plugin/zoom-js/zoom.js', async: true },
					{ src: 'plugin/notes/notes.js', async: true },

					{ src: 'https://cdnjs.cloudflare.com/ajax/libs/socket.io/2.0.3/socket.io.js', async: true },
        	        { src: Reveal.getQueryHash().s ?
		            'plugin/multiplex/master.js' :
								'plugin/multiplex/client.js', async: true }
				]
			});

		</script>

	</body>
</html>
